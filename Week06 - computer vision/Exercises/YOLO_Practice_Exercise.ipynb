{"cells":[{"cell_type":"markdown","id":"fd8284c7","metadata":{"id":"fd8284c7"},"source":["# Highway Vehicle Counting Practice Exercise\n"]},{"cell_type":"markdown","id":"90e8c1a5","metadata":{"id":"90e8c1a5"},"source":["In this exercise, you will use the YOLO (You Only Look Once) object detection model to analyze a video of highway traffic.\n","Your task is to count the number of cars that are leaving the highway (coming toward the camera) on the right side and the number of cars that are joining the road on the left side. The video can be found under `Datasets/Example.mp4`.\n","\n","## Objectives\n","- Load and process a video using OpenCV.\n","- Use the YOLO model to detect vehicles in each frame.\n","- Use OpenCV to manulate the video.\n","- Track vehicles as they move through the video frames.\n","- Count the number of vehicles leaving the highway on the right side.\n","- Count the number of vehicles joining the road on the left side."]},{"cell_type":"markdown","id":"c7269b0e","metadata":{"id":"c7269b0e"},"source":["## Setup Environment"]},{"cell_type":"markdown","id":"2fd3bce8","metadata":{"id":"2fd3bce8"},"source":["Before you begin, ensure you have the necessary libraries installed. You will need `opencv`, and `ultralytics` among others.\n","If these are not installed, you should install them."]},{"cell_type":"code","source":["!pip install ultralytics -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1JZhLUDnhHI","executionInfo":{"status":"ok","timestamp":1725094164139,"user_tz":-180,"elapsed":12661,"user":{"displayName":"Nasser Al-Saqer","userId":"07667036346117507952"}},"outputId":"a6b2ece1-2d11-4bb5-b8a0-321da38984b3"},"id":"p1JZhLUDnhHI","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m780.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.2/872.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":2,"id":"e48a05c4","metadata":{"vscode":{"languageId":"plaintext"},"id":"e48a05c4","executionInfo":{"status":"ok","timestamp":1725094356140,"user_tz":-180,"elapsed":8152,"user":{"displayName":"Nasser Al-Saqer","userId":"07667036346117507952"}}},"outputs":[],"source":["import cv2\n","from ultralytics import YOLO"]},{"cell_type":"markdown","id":"a69c2ac2","metadata":{"id":"a69c2ac2"},"source":["## Load the YOLO Model"]},{"cell_type":"markdown","id":"145d70fc","metadata":{"id":"145d70fc"},"source":["You will first need to load the YOLO model. You can use a pre-trained YOLO model for this task.\n","Write the code to load the YOLO model below:\n"]},{"cell_type":"code","execution_count":3,"id":"7e580e4a","metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"7e580e4a","executionInfo":{"status":"ok","timestamp":1725094356857,"user_tz":-180,"elapsed":721,"user":{"displayName":"Nasser Al-Saqer","userId":"07667036346117507952"}},"outputId":"cc3ac42e-fc6a-4376-b918-d4549a4b3760"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.25M/6.25M [00:00<00:00, 71.6MB/s]\n"]}],"source":["model = YOLO('yolov8n.pt')"]},{"cell_type":"markdown","id":"cf691ac8","metadata":{"id":"cf691ac8"},"source":["## Prepare the Video Capture"]},{"cell_type":"markdown","metadata":{"id":"13_by5zcl-mV"},"source":["Create a variable to capture the video frames, you can use `cv2.VideoCapture()` to achive this."],"id":"13_by5zcl-mV"},{"cell_type":"code","execution_count":4,"id":"81cfbca1","metadata":{"vscode":{"languageId":"plaintext"},"id":"81cfbca1","executionInfo":{"status":"ok","timestamp":1725094441351,"user_tz":-180,"elapsed":394,"user":{"displayName":"Nasser Al-Saqer","userId":"07667036346117507952"}}},"outputs":[],"source":["cap = cv2.VideoCapture('/content/Example.mp4')\n","assert cap.isOpened(), \"Cannot open video\""]},{"cell_type":"markdown","id":"48757309","metadata":{"id":"48757309"},"source":["## Get Video Information"]},{"cell_type":"markdown","id":"b4f5d5bc","metadata":{"id":"b4f5d5bc"},"source":["You can use `cv2` library to get these information fro the `VideoCapture()` variable you created to extract these information:\n","* `height`: Video's height.\n","* `width`: Video's width.\n","* `fps`: Video's frames."]},{"cell_type":"code","execution_count":5,"id":"cb8e5ceb","metadata":{"vscode":{"languageId":"plaintext"},"id":"cb8e5ceb","executionInfo":{"status":"ok","timestamp":1725094688447,"user_tz":-180,"elapsed":386,"user":{"displayName":"Nasser Al-Saqer","userId":"07667036346117507952"}}},"outputs":[],"source":["height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","fps = int(cap.get(cv2.CAP_PROP_FPS))"]},{"cell_type":"code","source":["print(\"Video Width:\", width)\n","print(\"Video Height:\", height)\n","print(\"Video FPS:\", fps)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"foNj-hOEqANg","executionInfo":{"status":"ok","timestamp":1725094693752,"user_tz":-180,"elapsed":413,"user":{"displayName":"Nasser Al-Saqer","userId":"07667036346117507952"}},"outputId":"3ee51cf3-61eb-4a6e-c614-dcc1e2ad2bef"},"id":"foNj-hOEqANg","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Video Width: 1280\n","Video Height: 720\n","Video FPS: 25\n"]}]},{"cell_type":"markdown","id":"3f241495","metadata":{"id":"3f241495"},"source":["## Prepare Video Writer to Store the Output"]},{"cell_type":"markdown","id":"9ef61a34","metadata":{"id":"9ef61a34"},"source":["Create a variable that uses `cv2.VideoCapture()` to save the video with the bounding boxes and the counted cars on both sides. You will need to make the video with the same `fps`, `width`, `height`, and specify the codec and output path of the video."]},{"cell_type":"code","execution_count":8,"id":"449562c2","metadata":{"vscode":{"languageId":"plaintext"},"id":"449562c2","executionInfo":{"status":"ok","timestamp":1725094857266,"user_tz":-180,"elapsed":394,"user":{"displayName":"Nasser Al-Saqer","userId":"07667036346117507952"}}},"outputs":[],"source":["# Another way\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter('object_counting_output.mp4', fourcc, fps, (width, height))"]},{"cell_type":"markdown","id":"067dbc12","metadata":{"id":"067dbc12"},"source":["## Process Video Frames and Identify Vehicles on the Right and Left Sides"]},{"cell_type":"markdown","id":"aa695d88","metadata":{"id":"aa695d88"},"source":["For each frame in the video, use the YOLO model to detect and track vehicles. You'll need to write a loop that processes each frame and applies the YOLO model.\n","In each frame, after detecting the vehicles, determine whether they are on the left or right side of the highway.\n","You can use the position of the bounding boxes provided by YOLO to do this.\n","* The video should display bounding boxes around the detected objects.\n","* The video should display the confidence along side with the object id and class id of each detected and tracked object.\n","* The video display the number of vehicles on the left side.\n","* The video display the number of vehicles on the right side.\n","* The video should display the line in which you counted the objects that have crossed it and counted."]},{"cell_type":"code","execution_count":null,"id":"877d1d56","metadata":{"vscode":{"languageId":"plaintext"},"id":"877d1d56"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"71d3083e","metadata":{"id":"71d3083e"},"source":["## Save and Submit Your Work"]},{"cell_type":"markdown","id":"ae5e33ac","metadata":{"id":"ae5e33ac"},"source":["In the actual exam you will be asked to submit both the notebook and the output video"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}